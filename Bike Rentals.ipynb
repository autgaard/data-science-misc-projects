{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Predicting Bike Rentals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What the project is about:** Many U.S. cities have communal bike sharing stations where you can rent bicycles by the hour or day. Washington, D.C. is one of these cities. The District collects detailed data on the number of bicycles people rent by the hour and day.\n",
    "\n",
    "Hadi Fanaee-T at the University of Porto compiled this data into a [CSV file](http://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset), which I'll work with in this project. \n",
    "\n",
    "**Goal of the project:** My goal is to try to predict the total number of bikes people rented in a given hour.  To accomplish this, I'll create a few different machine learning models and evaluate their performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
       "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
       "1        2  2011-01-01       1   0     1   1        0        6           0   \n",
       "2        3  2011-01-01       1   0     1   2        0        6           0   \n",
       "3        4  2011-01-01       1   0     1   3        0        6           0   \n",
       "4        5  2011-01-01       1   0     1   4        0        6           0   \n",
       "\n",
       "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
       "0           1  0.24  0.2879  0.81        0.0       3          13   16  \n",
       "1           1  0.22  0.2727  0.80        0.0       8          32   40  \n",
       "2           1  0.22  0.2727  0.80        0.0       5          27   32  \n",
       "3           1  0.24  0.2879  0.75        0.0       3          10   13  \n",
       "4           1  0.24  0.2879  0.75        0.0       0           1    1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "bike_rentals = pandas.read_csv(\"bike_rental_hour.csv\")\n",
    "bike_rentals.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's look at a histogram of the `cnt` column of `bike_rentals` and examine the distribution of total rentals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6972., 3705., 2659., 1660.,  987.,  663.,  369.,  188.,  139.,\n",
       "          37.]),\n",
       " array([  1. ,  98.6, 196.2, 293.8, 391.4, 489. , 586.6, 684.2, 781.8,\n",
       "        879.4, 977. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEACAYAAABYq7oeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBwCAw/8HkCb6D0gnLtwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f181131bef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(bike_rentals[\"cnt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I'll use the [corr](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.corr.html) method on the `bike_rentals` dataframe to explore how each column is correlated with `cnt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "instant       0.278379\n",
       "season        0.178056\n",
       "yr            0.250495\n",
       "mnth          0.120638\n",
       "hr            0.394071\n",
       "holiday      -0.030927\n",
       "weekday       0.026900\n",
       "workingday    0.030284\n",
       "weathersit   -0.142426\n",
       "temp          0.404772\n",
       "atemp         0.400929\n",
       "hum          -0.322911\n",
       "windspeed     0.093234\n",
       "casual        0.694564\n",
       "registered    0.972151\n",
       "cnt           1.000000\n",
       "Name: cnt, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_rentals.corr()[\"cnt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "It can often be helpful to calculate features before applying machine learning models. Features can enhance the accuracy of models by introducing new information or distilling existing information.\n",
    "\n",
    "For example, the `hr` column in `bike_rentals` contains the hours during which bikes are rented, from 1 to 24. A machine treats each hour differently, without understanding that certain hours are related. I can introduce some order into the process by creating a new column with labels for `morning`, `afternoon`, `evening`, and `night`. This bundles similar times together, enabling the model to make better decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assign_label(hour):\n",
    "    if hour >=0 and hour < 6:\n",
    "        return 4\n",
    "    elif hour >=6 and hour < 12:\n",
    "        return 1\n",
    "    elif hour >= 12 and hour < 18:\n",
    "        return 2\n",
    "    elif hour >= 18 and hour <=24:\n",
    "        return 3\n",
    "\n",
    "bike_rentals[\"time_label\"] = bike_rentals[\"hr\"].apply(assign_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before I can begin applying machine learning algorithms, I'll need to split the data into training and testing sets. This will enable me to train an algorithm using the training set, and evaluate its accuracy on the testing set. If I train an algorithm on the training data, then evaluate its performance on the same data, I can get an unrealistically low error value, due to overfitting.\n",
    "\n",
    "Based on your explorations of the `cnt` column, the mean squared error metric makes the most sense to evaluate the performance of the machine learning algorithms. MSE works on continuous numeric data, which fits the data quite well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = bike_rentals.sample(frac=.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = bike_rentals.loc[~bike_rentals.index.isin(train.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression works best when predictors are linearly correlated to the target and also independent - in other words, they don't change meaning when I combine them with each other. The good thing about linear regression is that it's fairly resistant to overfitting because it's straightforward. It also can be prone to underfitting the data, however, and not building a powerful enough model. This means that linear regression usually isn't the most accurate option.\n",
    "\n",
    "With this in mind, I'll need to ignore the `casual` and `registered` columns because `cnt` is derived from them. If I'm trying to predict the number of people who rent bikes in a given hour (`cnt`), it doesn't make sense that I'd already know `casual` or `registered`, because those numbers are added together to get `cnt`.\n",
    "\n",
    "Below, I've created a list of predictor columns to use in training and predictions. I then use the [LinearRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) class from sklearn to train a machine learning algorithm on `train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "predictors = list(train.columns)\n",
    "predictors.remove(\"cnt\")\n",
    "predictors.remove(\"casual\")\n",
    "predictors.remove(\"registered\")\n",
    "predictors.remove(\"dteday\")\n",
    "\n",
    "reg = LinearRegression()\n",
    "\n",
    "reg.fit(train[predictors], train[\"cnt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17207.91668099656"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "predictions = reg.predict(test[predictors])\n",
    "\n",
    "numpy.mean((predictions - test[\"cnt\"]) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error between the predictions and the actual values is very high, which may be due to the fact that the data has a few extremely high rental counts, but otherwise mostly low counts. Larger errors are penalized more with MSE, which leads to a higher total error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'm ready to apply the decision tree algorithm. I'll be able to compare the decision tree algorithm error with the error from linear regression, which will enable me to pick the right algorithm for this dataset.\n",
    "\n",
    "Decision trees tend to predict outcomes much more reliably than linear regression models, because a decision tree is a fairly complex model. It also tends to overfit, particularly when I don't tweak parameters like maximum depth and minimum number of samples per leaf. Decision trees are also prone to instability - small changes in the input data can result in a very different output model.\n",
    "\n",
    "Below, I've used  the [DecisionTreeRegressor](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html) class to fit a decision tree algorithm to the `train` data. I then made predictions using the DecisionTreeRegressor class on `test`. To finish, I calculated the error between the predictions and the actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_split=1e-07,\n",
       "           min_samples_leaf=5, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "           splitter='best')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "reg = DecisionTreeRegressor(min_samples_leaf=5)\n",
    "\n",
    "reg.fit(train[predictors], train[\"cnt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2755.6389217466995"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = reg.predict(test[predictors])\n",
    "\n",
    "numpy.mean((predictions - test[\"cnt\"]) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3436.6609209180415"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = DecisionTreeRegressor(min_samples_leaf=2)\n",
    "\n",
    "reg.fit(train[predictors], train[\"cnt\"])\n",
    "\n",
    "predictions = reg.predict(test[predictors])\n",
    "\n",
    "numpy.mean((predictions - test[\"cnt\"]) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By taking the nonlinear predictors into account, the decision tree regressor appears to have much higher accuracy than linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can now apply the random forest algorithm, which improves on the decision tree algorithm. Random forests tend to be much more accurate than simple models like linear regression. Due to the way random forests are constructed, they tend to overfit much less than decision trees. Random forests are prone to overfitting, so it's important to tune parameters like maximum depth and minimum samples per leaf.\n",
    "\n",
    "Just as I did before, I will use the [RandomForestRegressor](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) class to fit a random forest algorithm to the `train` data, then make predictions using the RandomForestRegressor class on `test`. I will then calculate the error between the predictions and the actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=5,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "reg = RandomForestRegressor(min_samples_leaf=5)\n",
    "reg.fit(train[predictors], train[\"cnt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024.5025182295424"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = reg.predict(test[predictors])\n",
    "\n",
    "numpy.mean((predictions - test[\"cnt\"]) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By removing some of the sources of overfitting, the random forest accuracy is improved over the decision tree accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
